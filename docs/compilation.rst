======================
Compilation feature
======================


Overall
=========

Construct 2.9 adds an experimental feature: compiling user made constructs into faster (but less feature-rich) code. If you are familiar with Kaitai Struct, an alternative framework to Construct, Kaitai compiles its own yaml-based language schemas into Python modules. Construct on the other hand, defines schemas in Python and compiles it into also a Python module. Once you define a construct, you can use it to parse and build strings without compilation. Compilation has only one purpose: performance. Compiled constructs cannot do anything more than original constructs, in fact, they have restricted capabilities (some classes do not compile, or compile only under certain circumstances).


Requirements
---------------

Compilation feature requires Construct 2.9 and Python 3.4. More importantly, you should manually inspect the generated code for correctness and have a test suite of your own. Construct aims to be reliable, but there is inherent risk in using experimental features. The compiler makes some assumptions, and generates a code that "takes shortcuts".


Restrictions
---------------

compiled code only parses, no building yet implemented

Bytewise is not compilable

Range compiles only for Array instances

RepeatUntil is not compilable

Embedded is not compilable

Select Optional Switch are not yet implemented

StopIf is not compilable

Pointer Peek Terminated are not yet implemented

Restreamed Rebuffered are not compilable

RawCopy Checksum Compressed are not compilable

BitsSwapped is not yet implemented

Lazy* OnDemand are not compilable

Mapping* are not compilable

Enum FlagsEnum are not yet implemented

Adapters and validators are not compilable

CString is not yet implemented

Lambdas (unlike this expressions) are not compilable


Compiling schemas
===================

Every construct (even those that do not compile) has a parameter-less `compile` method that returns also a construct (instance of Compiled class). Note that compiling takes a substantial amount of time (compared to parsing a single blob) so it may be a good idea to compile something that is used for processing giga-sized data or multiple blobs of data, but should not be overused.
That compiled instance has `parse` and `build` methods like any other class.

>>> st = Struct("num" / Byte)
>>> st.parse(b"\x01")
Container(num=1)
>>> st2 = st.compile()
>>> st2.parse(b"\x01")
Container(num=1)

Compiled instance has a unique `source` field that holds the generated code as string and also has a unique method `tofile` that saves the generated source code to a file, for your inspection for example. You can also import such a module from a Python script.

>>> st2.source
"... schema code ..."
>>> st2.tofile("schema1.py")
>>> import schema1

Performance boost can be easily measured: 

>>> from timeit import timeit
>>> timeit(lambda: st.parse(sampledata))
>>> timeit(lambda: st2.parse(sampledata))

Correctness can be automatically tested:

>>> assert st.parse(sampledata) == st2.parse(sampledata)


Motivation
============

The code generated by compiler and core classes have essentially same functionality, but there is a noticable difference in performance. This chapter explains the difference by comparing `Struct FormatField BytesInteger Bytes` classes, including using a context. Example construct:

::

    Struct(
        "num8" / Int8ub,
        "num24" / Int24ub,
        "data" / Bytes(this.num8),
    )

Compiled parsing code:

::

    def read_bytes(io, count):
        assert count >= 0
        data = io.read(count)
        assert len(data) == count
        return data
    from struct import pack, unpack, calcsize
    def parse_struct_1(io, context):
        class FIELDS:
            __slots__ = ['num8', 'num24', 'data']
        this = FIELDS()
        this.num8 = unpack('>B', read_bytes(io, 1))[0]
        this.num24 = int.from_bytes(read_bytes(io, 3), byteorder='big', signed=False)
        this.data = read_bytes(io, this.num8)
        return this
    def parseall(io, context):
        this = context
        return parse_struct_1(io, this)

Non-compiled parsing code:

::

    def _read_stream(stream, length):
        if length < 0:
            raise StreamError("length must be >= 0", length)
        data = stream.read(length)
        if len(data) != length:
            raise StreamError("could not read enough bytes, expected %d, found %d" % (length, len(data)))
        return data

    class FormatField(Bytes):
        def _parse(self, stream, context, path):
            try:
                data = _read_stream(stream, self.sizeof())
                return packer.unpack(self.fmtstr, data)[0]
            except Exception:
                raise FormatFieldError("packer %r error during parsing" % self.fmtstr)

    class BytesInteger(Construct):
        def _parse(self, stream, context, path):
            length = self.length(context) if callable(self.length) else self.length
            data = _read_stream(stream, length)
            if self.swapped:
                data = swapbytes(data, 1)
            return bytes2integer(data, self.signed)

    class Bytes(Construct):
        def _parse(self, stream, context, path):
            length = self.length(context) if callable(self.length) else self.length
            return _read_stream(stream, length)

    class Renamed(Subconstruct):
        def _parse(self, stream, context, path):
            try:
                path += " -> %s" % (self.name)
                return self.subcon._parse(stream, context, path)
            except ConstructError as e:
                if "\n" in str(e):
                    raise
                raise e.__class__("%s\n    %s" % (e, path))

    class Struct(Construct):
        def _parse(self, stream, context, path):
            obj = Container()
            context = Container(_ = context)
            for sc in self.subcons:
                try:
                    subobj = sc._parse(stream, context, path)
                    if sc.flagembedded:
                        if subobj is not None:
                            obj.update(subobj)
                            context.update(subobj)
                    else:
                        if sc.name:
                            obj[sc.name] = subobj
                            context[sc.name] = subobj
                except StopIteration:
                    break
            return obj

There are several "shortcuts" that the compiled code does:

Function calls are relatively expensive, so inlined expression is faster than a function with one-liner return statement. Therefore FormatField compiles into `struct.unpack(..., read_bytes(io, ...))` directly.

Literals like 1 and '>B' are faster than variable (or object field) lookup, or passing function arguments. Therefore each instance of FormatField compiles into a similar expression but with different format-strings and byte-counts inlined, usually literals.

If statement (or conditional ternary operator) with two possible expressions is slower than just one or the other expression. Therefore, for example, BytesInteger does a lookup to check if field is swapped, but compiled BytesInteger simply inlines 'big' or 'little' literal. Moreover, Struct checks if each subcon has a name and then inserts a value into the context dictionary, but compiled Struct simply has an assignment or not. Also, since compiler does not support embedding, there is no checking if each subcon is embedded. Also compiler does not support StopIf class, so no exception catching is done.

Building two identical dictionaries is slower than building just one. Struct maintains two dictionaries (called obj and context) which differ only by _ key, but compiled Struct does something simpler.

This expressions (not lambdas) are expensive to compute but something like "this.field" in a compiled code is merely one object field lookup. Lambdas are not supported by compiler.
